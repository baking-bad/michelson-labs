(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{384:function(t,s,a){"use strict";a.r(s);var n=a(43),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"chapter-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#chapter-7"}},[t._v("#")]),t._v(" Chapter 7")]),t._v(" "),a("p",[t._v("This new chapter will be the occasion to work a little more in-depth with two data types that are pretty important on a smart contract: strings and lists.")]),t._v(" "),a("p",[t._v("In most projects that you will work on, you will probably have to manipulate strings. Whether you want to save some data provided by your users or compare inputs, strings are an essential component of smart contracts. Unlike other smart contract languages whose developers have been asking for these features for years (for example Solidity), Michelson offers string manipulation functions out of the box. Although still limited compared to other high level languages, these functions will still provide enough flexibility to get the job done.")]),t._v(" "),a("p",[t._v("Once you have strings in your smart contract, what about storing them somewhere? Lists could be the perfect place for that! Michelson offers different possibilities in terms of storage for multiple pieces of data and lists are one of them. Before choosing a list for your needs, you must know more about what make them different and how they work. This will have no more secret for you at the end of this tutorial!")]),t._v(" "),a("h2",{attrs:{id:"strings-and-string-manipulations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#strings-and-string-manipulations"}},[t._v("#")]),t._v(" Strings and string manipulations")]),t._v(" "),a("p",[t._v("We have already worked with strings in the previous chapters, so you should already be familiar with this type. Strings are one character or a series of characters delimited by double-quotes and including only the characters present in the English alphabet (and the escape character in "),a("a",{attrs:{href:"https://tezos.gitlab.io/whitedoc/michelson.html#constants",target:"_blank",rel:"noopener noreferrer"}},[t._v("certain circumstances"),a("OutboundLink")],1),t._v("). Strings are comparable values that can be added to contract from different sources: they can come from the parameter, the storage or the "),a("strong",[a("code",[t._v("PUSH")])]),t._v(" instruction.")]),t._v(" "),a("p",[t._v("Once the string is present in the stack, you can work with it!"),a("br"),t._v("\nFirst, you can check the length of the string with the "),a("strong",[a("code",[t._v("SIZE")])]),t._v(" opcode:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SIZE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("0")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * 0)\nCAR / ('tezos' * 0) => 'tezos'\nSIZE / 'tezos' => 5\nNIL / _ => []\nPAIR / [] : 5 => ([] * 5)\nEND %default / ([] * 5) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                    ")]),a("th",[t._v("value                                 ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("nat")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("5")])])])])])]),t._v(" "),a("p",[t._v("As expected, the length of the string "),a("em",[t._v('"Tezos"')]),t._v(" is "),a("code",[t._v("5")]),t._v(". Note that the length is returned as a "),a("code",[t._v("nat")]),t._v(" because negative length are not possible."),a("br"),t._v("\nKnowing the length of a string can be useful if you want to limit the size of the strings saved into your contract. Let's write an example that will reject string parameters if their length exceeds "),a("code",[t._v("5")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("DUP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SIZE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("5")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token variable"},[t._v("IFCMPLT")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token variable"},[t._v("FAIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('""')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * '')\nCAR / ('tezos' * '') => 'tezos'\nDUP / 'tezos' => 'tezos' : 'tezos'\nSIZE / 'tezos' => 5\nPUSH / _ => 5\nCOMPARE / 5 : 5 => 0\nLT / 0 => False\nIF / False => _\nNIL / _ => []\nPAIR / [] : 'tezos' => ([] * 'tezos')\nEND %default / ([] * 'tezos') => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                       ")]),a("th",[t._v("value                                     ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("tezos")])])])])])]),t._v(" "),a("p",[t._v('If you add another character to "tezos", you will see the contract fail ðŸ˜Š')]),t._v(" "),a("p",[t._v("One of the most common actions on strings is concatenation. Michelson provides an instruction that allows you to put two separate strings together: "),a("strong",[a("code",[t._v("CONCAT")])]),t._v(". This is how it works:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Hello "')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONCAT")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('""')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('Tezos' * '')\nCAR / ('Tezos' * '') => 'Tezos'\nPUSH / _ => 'Hello '\nCONCAT / 'Hello ' : 'Tezos' => 'Hello Tezos'\nNIL / _ => []\nPAIR / [] : 'Hello Tezos' => ([] * 'Hello Tezos')\nEND %default / ([] * 'Hello Tezos') => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                       ")]),a("th",[t._v("value                                           ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Hello Tezos")])])])])])]),t._v(" "),a("p",[t._v('This smart contract does a very simple thing: it takes a string as a parameter and put it together with "Hello " before saving it in the storage. When using '),a("strong",[a("code",[t._v("CONCAT")])]),t._v(", just make sure you have two strings on top of the stack and that they are in the right order, the element 1 will be the first one in the new string and element 2 will be the second one.")]),t._v(" "),a("p",[t._v("If you want to concatenate multiple strings, you just have to add them to the stack and concatenate the "),a("strong",[a("code",[t._v("CONCAT")])]),t._v(" instructions!")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Tezos "')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Hello "')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONCAT")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONCAT")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"World"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('""')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('World' * '')\nCAR / ('World' * '') => 'World'\nPUSH / _ => 'Tezos '\nPUSH / _ => 'Hello '\nCONCAT / 'Hello ' : 'Tezos ' => 'Hello Tezos '\nCONCAT / 'Hello Tezos ' : 'World' => 'Hello Tezos World'\nNIL / _ => []\nPAIR / [] : 'Hello Tezos World' => ([] * 'Hello Tezos World')\nEND %default / ([] * 'Hello Tezos World') => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                       ")]),a("th",[t._v("value                                                 ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Hello Tezos World")])])])])])]),t._v(" "),a("p",[t._v("The opposite action is "),a("strong",[a("code",[t._v("SLICE")])]),t._v(": instead of putting two strings together, we are cutting one in pieces! This instruction takes three parameters: the starting point for the slice, the character length you want to slice and the string. Let's observe a few examples:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("unit")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("unit")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("BEGIN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("Unit")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("Unit")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("DROP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token comment"},[t._v("## Pushes a string and extract the first 6 characters")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("@string_to_slice")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"BakingBad"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("@length")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("6")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## length")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("@offset")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("0")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## offset")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\nBEGIN %default / _ => (Unit * Unit)\nDROP / (Unit * Unit) => _\nPUSH / _ => 'BakingBad'\nPUSH / _ => 6\nPUSH / _ => 0\nDUMP => [0, 6, 'BakingBad']")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                       ")]),a("th",[t._v("value                                         ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("nat")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("nat")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("6")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("2")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("BakingBad")])])])])])]),t._v(" "),a("p",[t._v("This is how the stack looks like before the slicing begins...")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token operator"},[t._v("SLICE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("SLICE / 0 : 6 : 'BakingBad' => 'Baking'?")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                                ")]),a("th",[t._v("value                                      ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("option (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Baking")])])])])])]),t._v(" "),a("p",[t._v("You probably notice that the result of "),a("strong",[a("code",[t._v("SLICE")])]),t._v(" is wrapped in an "),a("code",[t._v("option")]),t._v(" value. If the offset or the length you set go beyond the bounds of the string, the opcode returns "),a("code",[t._v("None")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token operator"},[t._v("DROP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"BakingBad"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("6")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## length")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("6")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## offset")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SLICE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("DROP / 'Baking'? => _\nPUSH / _ => 'BakingBad'\nPUSH / _ => 6\nPUSH / _ => 6\nSLICE / 6 : 6 : 'BakingBad' => None")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                       ")]),a("th",[t._v("value                                    ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("option")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("None")])])])])])]),t._v(" "),a("p",[t._v("Obviously, you are not limited to extract slices of strings from the first character, you can start at whichever position you like, keeping in mind the bounds of the string:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token operator"},[t._v("DROP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"BakingBadIsAwesome"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## length")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("11")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## offset")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SLICE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("DROP / None => _\nPUSH / _ => 'BakingBadIsAwesome'\nPUSH / _ => 7\nPUSH / _ => 11\nSLICE / 11 : 7 : 'BakingBadIsAwesome' => 'Awesome'?")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                                ")]),a("th",[t._v("value                                       ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("option (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Awesome")])])])])])]),t._v(" "),a("p",[t._v("Slicing a string in two pieces is going to ask for a little extra work but it is totally possible. Here is how to do it:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token operator"},[t._v("DROP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"BakingBadIsAwesome"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Push the string to slice in two")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("DUP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Duplicate the string")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## The length of the first piece")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("0")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## The offset of the first piece")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SLICE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Extract the first piece of the string")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Get the duplicated original string on top of the stack")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## The lenght of the second piece")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## The offset of the second piece")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SLICE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Extract the second piece of the string")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token comment"},[t._v("## Put the pieces in the right order")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("DROP / 'Awesome'? => _\nPUSH / _ => 'BakingBadIsAwesome'\nDUP / 'BakingBadIsAwesome' => 'BakingBadIsAwesome' : 'BakingBadIsAwesome'\nPUSH / _ => 9\nPUSH / _ => 0\nSLICE / 0 : 9 : 'BakingBadIsAwesome' => 'BakingBad'?\nSWAP / 'BakingBad'? : 'BakingBadIsAwesome' => 'BakingBadIsAwesome' : 'BakingBad'?\nPUSH / _ => 9\nPUSH / _ => 9\nSLICE / 9 : 9 : 'BakingBadIsAwesome' => 'IsAwesome'?\nSWAP / 'IsAwesome'? : 'BakingBad'? => 'BakingBad'? : 'IsAwesome'?\nDUMP => ['BakingBad'?, 'IsAwesome'?]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                                ")]),a("th",[t._v("value                                         ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("option (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("BakingBad")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("option (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("IsAwesome")])])])])])]),t._v(" "),a("p",[t._v("The last instruction in our tool box for strings in Michelson is "),a("strong",[a("code",[t._v("COMPARE")])]),t._v(". As it does it for other types, the instruction compares two strings. You can then use it with the usual macros to check if two strings are the same or are different:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("DROP_ALL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token variable"},[t._v("CMPEQ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("@first_example")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"bakingbad"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"BakingBad"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token variable"},[t._v("CMPEQ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("@second_example")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("PUSH / _ => 'tezos'\nPUSH / _ => 'tezos'\nCOMPARE / 'tezos' : 'tezos' => 0\nEQ / 0 => True\nPUSH / _ => 'bakingbad'\nPUSH / _ => 'BakingBad'\nCOMPARE / 'BakingBad' : 'bakingbad' => -1\nEQ / -1 => False\nDUMP => [False, True]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                     ")]),a("th",[t._v("value                                     ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("bool")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("False")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("bool")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("True")])])])])])]),t._v(" "),a("p",[t._v("As you can see, "),a("strong",[a("code",[t._v("COMPARE")])]),t._v(" is case-sensitive, so it is very important to verify this won't produce false negative results.")]),t._v(" "),a("h2",{attrs:{id:"working-with-lists"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#working-with-lists"}},[t._v("#")]),t._v(" Working with lists")]),t._v(" "),a("p",[t._v("After manipulating strings, you may want to save them in the storage of the smart contract. Michelson offers different solutions for that, for example sets and maps, but you may prefer a "),a("em",[t._v("list")]),t._v(". A list is a special structure that contains different values of the same type. One of its characteristics is that a list is "),a("em",[t._v("immutable")]),t._v(", meaning that when you want to add an element to a list, you actually create a new list made of the new element in the first position (which we call the "),a("em",[t._v("head")]),t._v(") and the elements of the previous list starting at the second position (the previous list is called the "),a("em",[t._v("tail")]),t._v("). Lists are also ordered, which means that their elements are in a specific order.")]),t._v(" "),a("p",[t._v("You probably remember how to create an empty list from the contracts we already wrote so far, with "),a("code",[t._v('NIL "type"')]),t._v(". The "),a("strong",[a("code",[t._v("NIL")])]),t._v(" instruction creates a new empty list that will accept elements of the type you specified. For example, "),a("strong",[a("code",[t._v("NIL operation")])]),t._v(" is a list that accepts elements of type "),a("code",[t._v("operation")]),t._v(". Once you created an empty list, you can easily add an element with the "),a("strong",[a("code",[t._v("CONS")])]),t._v(" instruction. First, you push the element onto the stack, next to the list before using "),a("strong",[a("code",[t._v("CONS")])]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONS")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * [])\nCAR / ('tezos' * []) => 'tezos'\nNIL / _ => []\nSWAP / [] : 'tezos' => 'tezos' : []\nCONS / 'tezos' : [] => ['tezos']\nNIL / _ => []\nPAIR / [] : ['tezos'] => ([] * ['tezos'])\nEND %default / ([] * ['tezos']) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                              ")]),a("th",[t._v("value                                         ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("['tezos']")])])])])])]),t._v(" "),a("p",[t._v("If you wish, you can also push an existing list onto the stack like so:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("DROP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token number"},[t._v('"baking"')]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"bad"')]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * [])\nDROP / ('tezos' * []) => _\nPUSH / _ => ['baking', 'bad']\nNIL / _ => []\nPAIR / [] : ['baking', 'bad'] => ([] * ['baking', 'bad'])\nEND %default / ([] * ['baking', 'bad']) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                              ")]),a("th",[t._v("value                                                 ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("['baking', 'bad']")])])])])])]),t._v(" "),a("p",[t._v("After the list has been added to the stack, you can add new elements at the beginning ("),a("em",[t._v("the head")]),t._v("):")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token number"},[t._v('"baking"')]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"bad"')]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONS")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * [])\nCAR / ('tezos' * []) => 'tezos'\nPUSH / _ => ['baking', 'bad']\nSWAP / ['baking', 'bad'] : 'tezos' => 'tezos' : ['baking', 'bad']\nCONS / 'tezos' : ['baking', 'bad'] => ['tezos', 'baking', 'bad']\nNIL / _ => []\nPAIR / [] : ['tezos', 'baking', 'bad'] => ([] * ['tezos', 'baking', 'bad'])\nEND %default / ([] * ['tezos', 'baking', 'bad']) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                              ")]),a("th",[t._v("value                                                          ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("['tezos', 'baking', 'bad']")])])])])])]),t._v(" "),a("p",[t._v("Sometimes, you may want to check a list and implement different behaviors if the list is empty or not. In this case, you can use "),a("strong",[a("code",[t._v("IF_CONS")])]),t._v(" which verifies if there is a head to the provided list. Like the other "),a("strong",[a("code",[t._v("IF")])]),t._v(" instructions, you need to create two branches, the first one will be executed if "),a("strong",[a("code",[t._v("IF_CONS")])]),t._v(" is "),a("code",[t._v("True")]),t._v(" and the second one will be executed if it is "),a("code",[t._v("False")]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("DUP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CDR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("IF_CONS")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token variable"},[t._v("FAIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONS")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"tezos"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token comment"},[t._v('## RUN %default "tezos" { "test" } ;')]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ('tezos' * [])\nDUP / ('tezos' * []) => ('tezos' * []) : ('tezos' * [])\nCAR / ('tezos' * []) => 'tezos'\nSWAP / 'tezos' : ('tezos' * []) => ('tezos' * []) : 'tezos'\nCDR / ('tezos' * []) => []\nIF_CONS / [] => _\nNIL / _ => []\nSWAP / [] : 'tezos' => 'tezos' : []\nCONS / 'tezos' : [] => ['tezos']\nNIL / _ => []\nPAIR / [] : ['tezos'] => ([] * ['tezos'])\nEND %default / ([] * ['tezos']) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                              ")]),a("th",[t._v("value                                         ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (string)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("['tezos']")])])])])])]),t._v(" "),a("p",[t._v("Be careful as "),a("strong",[a("code",[t._v("IF_CONS")])]),t._v(" is going to remove the list you are checking. You should duplicate it with "),a("strong",[a("code",[t._v("DUP")])]),t._v(" first or if you are checking for an empty string like in this example, you can just push another empty string."),a("br"),t._v("\nIf you comment the first "),a("code",[t._v("RUN")]),t._v(" and comment out the second, you will see the expected behavior of the contract as it fails when the list in the storage is not empty.")]),t._v(" "),a("p",[t._v("Another useful instruction to check lists is "),a("strong",[a("code",[t._v("SIZE")])]),t._v(" which returns the number of elements in a list as a "),a("code",[t._v("nat")]),t._v(" (as usual, the number of elements cannot be negative):")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("nat")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("code")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SIZE")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("NIL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("operation")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PAIR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("RUN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token attr-name"},[t._v("%default")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("4")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("6")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("0")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\ncode: updated\nBEGIN %default / _ => ([7, 4, 6] * 0)\nCAR / ([7, 4, 6] * 0) => [7, 4, 6]\nSIZE / [7, 4, 6] => 3\nNIL / _ => []\nPAIR / [] : 3 => ([] * 3)\nEND %default / ([] * 3) => _")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Operations")]),a("h4",[t._v("Storage")]),a("table",[a("thead",[a("tr",[a("th",[t._v("type                                    ")]),a("th",[t._v("value                                 ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("nat")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("3")])])])])])]),t._v(" "),a("p",[t._v("This is a very simple contract that saves in its storage the length of a list. Try to add or remove elements in the list to see it work ðŸ˜Š")]),t._v(" "),a("p",[t._v("One of the powers of list is that they are "),a("em",[t._v("iterable")]),t._v(", it means that you can go through the elements one by one, either to check them or modify them. Michelson offers two instructions to loop through lists: "),a("strong",[a("code",[t._v("ITER")])]),t._v(" and "),a("strong",[a("code",[t._v("MAP")])]),t._v(". Although they work in a very similar way, they yield very different results. Let's start with "),a("strong",[a("code",[t._v("ITER")])]),t._v(". One of the best ways to understand what it does is to see it in action:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("storage")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("parameter")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("BEGIN")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("3")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("0")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("CAR")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("storage: updated\nparameter: updated\nBEGIN %default / _ => ([7, 9, 3] * 0)\nCAR / ([7, 9, 3] * 0) => [7, 9, 3]\nDUMP => [[7, 9, 3]]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                           ")]),a("th",[t._v("value                                         ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (int)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("[7, 9, 3]")])])])])])]),t._v(" "),a("p",[t._v("This part is simple, we create a new contract and use a list of "),a("code",[t._v("int")]),t._v(" as a parameter before extracting the list and putting it on top of the stack. Now comes "),a("strong",[a("code",[t._v("ITER")])]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token operator"},[t._v("ITER")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("ITER / [7, 9, 3] => 7\nITER / _ => 9\nITER / _ => 3\nDUMP => [3, 9, 7]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                    ")]),a("th",[t._v("value                                 ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("3")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("9")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("2")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("7")])])])])])]),t._v(" "),a("p",[t._v("In its simplest form, "),a("strong",[a("code",[t._v("ITER")])]),t._v(" only takes a "),a("em",[t._v("body expression")]),t._v(" (the two curly braces) and runs every element of the list against the code inside the curly braces. The first element is pushed onto the stack and the instructions inside the curly braces are run as usual. When there are no more instructions to run, "),a("strong",[a("code",[t._v("ITER")])]),t._v(" pushes the second element of the list onto the stack, runs the instructions, and so on until the end of the list.")]),t._v(" "),a("p",[t._v("To demonstrate it, we could take each element of the list and add "),a("code",[t._v("2")]),t._v(" to it:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("DROP_ALL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("3")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("ITER")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("2")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("ADD")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("PUSH / _ => [7, 9, 3]\nITER / [7, 9, 3] => 7\nPUSH / _ => 2\nADD / 2 : 7 => 9\nITER / _ => 9\nPUSH / _ => 2\nADD / 2 : 9 => 11\nITER / _ => 3\nPUSH / _ => 2\nADD / 2 : 3 => 5\nDUMP => [5, 11, 9]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                    ")]),a("th",[t._v("value                                  ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("5")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("11")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("2")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("int")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("9")])])])])])]),t._v(" "),a("p",[t._v("First observation from this code snippet, "),a("strong",[a("code",[t._v("ITER")])]),t._v(" removes the list from the stack. Make sure to duplicate it if you need it later."),a("br"),t._v("\nNext, the elements present in the stack are indeed the values from the list + "),a("code",[t._v("2")]),t._v(" for each value. Remember that the first value in the list will be the last one in the resulting stack. Here is another example:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("DROP_ALL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"John"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Amir"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Stella"')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("ITER")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("string")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v('"Hello "')]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("CONCAT")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("PUSH / _ => ['John', 'Amir', 'Stella']\nITER / ['John', 'Amir', 'Stella'] => 'John'\nPUSH / _ => 'Hello '\nCONCAT / 'Hello ' : 'John' => 'Hello John'\nITER / _ => 'Amir'\nPUSH / _ => 'Hello '\nCONCAT / 'Hello ' : 'Amir' => 'Hello Amir'\nITER / _ => 'Stella'\nPUSH / _ => 'Hello '\nCONCAT / 'Hello ' : 'Stella' => 'Hello Stella'\nDUMP => ['Hello Stella', 'Hello Amir', 'Hello John']")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                       ")]),a("th",[t._v("value                                            ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Hello Stella")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("1")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Hello Amir")])])]),t._v(" "),a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("2")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("string")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("Hello John")])])])])])]),t._v(" "),a("p",[t._v("This is how you can greet all the people in a list! "),a("strong",[a("code",[t._v("ITER")])]),t._v(' goes through the list, takes the elements one by one and adds "Hello " in front of each name. You can add the level of complexity you want in the body expression (we\'ll keep that for the exercices!)')]),t._v(" "),a("p",[t._v("The second iterative instruction is "),a("strong",[a("code",[t._v("MAP")])]),t._v(". It works in a very similar fashion: you write a body expression next to the instruction with the instructions you want to apply to the elements of the list. However, this time, "),a("strong",[a("code",[t._v("MAP")])]),t._v(" is going to return a new list!")]),t._v(" "),a("p",[t._v("To observe clearly the difference between these two instruction, let's get our first example and replace "),a("strong",[a("code",[t._v("ITER")])]),t._v(" with "),a("strong",[a("code",[t._v("MAP")])]),t._v(":")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("DROP_ALL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("3")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("MAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("2")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("ADD")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("PUSH / _ => [7, 9, 3]\nMAP / [7, 9, 3] => 7\nPUSH / _ => 2\nADD / 2 : 7 => 9\nMAP / 9 => 9\nPUSH / _ => 2\nADD / 2 : 9 => 11\nMAP / 11 => 3\nPUSH / _ => 2\nADD / 2 : 3 => 5\nMAP / 5 => [9, 11, 5]\nDUMP => [[9, 11, 5]]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                           ")]),a("th",[t._v("value                                          ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (int)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("[9, 11, 5]")])])])])])]),t._v(" "),a("p",[t._v("As you can see, instead of having all the updated elements of the list one on top of the other in the stack, we have a single list where all the elements are in the same order as the previous one and are the result of the previous element value + "),a("code",[t._v("2")]),t._v(".")]),t._v(" "),a("p",[t._v("As you can imagine, this is a powerful feature, it allows you to update a list of values in the same exact way. We can go even further with the pattern and apply a conditional to it. For example, you can ask the contract to increase the value in the list only if it is above a certain value:")]),t._v(" "),a("div",{staticClass:"language-Michelson extra-class"},[a("pre",{staticClass:"language-Michelson"},[a("code",{staticClass:"language-Michelson"},[a("span",{staticClass:"token keyword"},[t._v("DROP_ALL")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("(")]),a("span",{staticClass:"token class-name"},[t._v("list")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(")")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("7")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("9")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("3")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("4")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("2")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token operator"},[t._v("MAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("DUP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("4")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("SWAP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token variable"},[t._v("IFCMPGT")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("PUSH")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token class-name"},[t._v("int")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token number"},[t._v("2")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token operator"},[t._v("ADD")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v("{")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token punctuation"},[t._v("}")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")]),a("span",{staticClass:"token keyword"},[t._v("DUMP")]),a("span",{staticClass:"token punctuation"},[t._v(" ")]),a("span",{staticClass:"token punctuation"},[t._v(";")]),a("span",{staticClass:"token punctuation"},[t._v("\n")])])])]),a("div",{staticClass:"stdout"},[a("pre",[a("span",{staticClass:"stream-name"},[t._v("stdout")]),a("br"),t._v("PUSH / _ => [7, 9, 3, 4, 2]\nMAP / [7, 9, 3, 4, 2] => 7\nDUP / 7 => 7 : 7\nPUSH / _ => 4\nSWAP / 4 : 7 => 7 : 4\nCOMPARE / 7 : 4 => 1\nGT / 1 => True\nIF / True => _\nPUSH / _ => 2\nADD / 2 : 7 => 9\nMAP / 9 => 9\nDUP / 9 => 9 : 9\nPUSH / _ => 4\nSWAP / 4 : 9 => 9 : 4\nCOMPARE / 9 : 4 => 1\nGT / 1 => True\nIF / True => _\nPUSH / _ => 2\nADD / 2 : 9 => 11\nMAP / 11 => 3\nDUP / 3 => 3 : 3\nPUSH / _ => 4\nSWAP / 4 : 3 => 3 : 4\nCOMPARE / 3 : 4 => -1\nGT / -1 => False\nIF / False => _\nMAP / 3 => 4\nDUP / 4 => 4 : 4\nPUSH / _ => 4\nSWAP / 4 : 4 => 4 : 4\nCOMPARE / 4 : 4 => 0\nGT / 0 => False\nIF / False => _\nMAP / 4 => 2\nDUP / 2 => 2 : 2\nPUSH / _ => 4\nSWAP / 4 : 2 => 2 : 4\nCOMPARE / 2 : 4 => -1\nGT / -1 => False\nIF / False => _\nMAP / 2 => [9, 11, 3, 4, 2]\nDUMP => [[9, 11, 3, 4, 2]]")])]),t._v(" "),a("div",{staticClass:"embedded-html"},[a("h4",[t._v("Stack updates")]),a("table",[a("thead",[a("tr",[a("th",[t._v("index                                 ")]),a("th",[t._v("type                                           ")]),a("th",[t._v("value                                                ")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("0")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("list (int)")])]),a("td",[a("pre",{staticStyle:{"text-align":"left"}},[t._v("[9, 11, 3, 4, 2]")])])])])])]),t._v(" "),a("p",[t._v("Don't let the long list of operations scare you, what happens under the hood is actually quite simple!"),a("br"),t._v("\nFirst, we add a new list of "),a("code",[t._v("int")]),t._v(" on top of the stack. Then, we loop through it using the "),a("strong",[a("code",[t._v("MAP")])]),t._v(" instruction. At the beginning of each iteration, the "),a("strong",[a("code",[t._v("MAP")])]),t._v(" instruction pushes the current value on the stack. We duplicate it (because we will need this value later if the comparison yields "),a("code",[t._v("True")]),t._v("), we push "),a("code",[t._v("4")]),t._v(" onto the stack for the comparison and we swap the position of the list value and the comparison element to put them in the right order. "),a("strong",[a("code",[t._v("IFCMPGT")])]),t._v(" checks if the top element is greater than the element below. If "),a("code",[t._v("True")]),t._v(", we push "),a("code",[t._v("2")]),t._v(" and add it to the number remaining on the stack. Otherwise, the value from the list is pushed into the new list with no change. You can use the same type for the new list (like in our example) or you can create a list with a different type too!")]),t._v(" "),a("Binder",{attrs:{filepath:"notebooks/tutorials/07/07_operation_string_list.ipynb"}})],1)}),[],!1,null,null,null);s.default=e.exports}}]);